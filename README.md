# Examples for OpenVino

This repo contains some examples how to run inferencing on Intel's OpenVino model server (OVMS). Refer to repository https://github.com/starwit/openvino-notebook how to run OpenVino model server with pre-installed models. 

Goal is to demonstrate how to connect to OVMS, send images and parse inferencing results. Focus are examples for EfficientDet and Yolo.

Please note, that this is an education repo and thus for every model there will be an individual script - small easy to understand code blocks.

# How to run
For every model there will be a Python script, that can be run without any parameters.

# References

OpenVino API Docs
* https://docs.openvino.ai/2022.1/ovms_docs_grpc_api.html
* https://docs.openvino.ai/2022.1/ovms_docs_rest_api.html
